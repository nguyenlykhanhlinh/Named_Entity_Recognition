{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# visualization libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# pytorch libraries\nimport torch # the main pytorch library\nimport torch.nn as nn # the sub-library containing Softmax, Module and other useful functions\nimport torch.optim as optim # the sub-library containing the common optimizers (SGD, Adam, etc.)\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# huggingface's transformers library\nfrom transformers import RobertaForTokenClassification, RobertaTokenizer\n\n# huggingface's datasets library\nfrom datasets import load_dataset\n\n# the tqdm library used to show the iteration progress\nimport tqdm\ntqdmn = tqdm.notebook.tqdm","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:25:14.274918Z","iopub.execute_input":"2023-11-12T16:25:14.275368Z","iopub.status.idle":"2023-11-12T16:25:18.545756Z","shell.execute_reply.started":"2023-11-12T16:25:14.275329Z","shell.execute_reply":"2023-11-12T16:25:18.544944Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:25:18.547194Z","iopub.execute_input":"2023-11-12T16:25:18.547615Z","iopub.status.idle":"2023-11-12T16:25:31.038259Z","shell.execute_reply.started":"2023-11-12T16:25:18.547587Z","shell.execute_reply":"2023-11-12T16:25:31.037317Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.10.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.17.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"roberta_version = 'roberta-base'\ntokenizer = RobertaTokenizer.from_pretrained(roberta_version)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:25:31.040170Z","iopub.execute_input":"2023-11-12T16:25:31.040546Z","iopub.status.idle":"2023-11-12T16:25:35.160317Z","shell.execute_reply.started":"2023-11-12T16:25:31.040508Z","shell.execute_reply":"2023-11-12T16:25:35.159338Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ef605fbd6c7494793fb18bcc68a9d97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ffbb72cb8c6476bb9a261fd9cb8273b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbd18feb915a411f8f98b3fdcdfc8374"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54be63485d8842729a68c44dc09f5d54"}},"metadata":{}}]},{"cell_type":"code","source":"# /kaggle/input/ner-vn-2023/train.txt\n# /kaggle/input/ner-vn-2023/test.txt\n# /kaggle/input/ner-vn-2023/dev.txt","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:25:35.162548Z","iopub.execute_input":"2023-11-12T16:25:35.162859Z","iopub.status.idle":"2023-11-12T16:25:35.166946Z","shell.execute_reply.started":"2023-11-12T16:25:35.162833Z","shell.execute_reply":"2023-11-12T16:25:35.165967Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def read_ner_data(file_path):\n    with open(file_path, 'r', encoding='utf-8') as file:\n        sentences, labels = [], []\n        current_sentence, current_labels = [], []\n        for line in file:\n            line = line.strip()\n            if not line:\n                if current_sentence:\n                    sentences.append(current_sentence)\n                    labels.append(current_labels)\n                    current_sentence, current_labels = [], []\n            else:\n                parts = line.split()\n                if len(parts) == 4:  # Đảm bảo rằng dòng có 4 phần\n                    word, pos_tag, chunk_tag, ner_tag = parts\n                    current_sentence.append(word)\n                    current_labels.append(ner_tag)\n        if current_sentence:\n            sentences.append(current_sentence)\n            labels.append(current_labels)\n    return {'sentences': sentences, 'ner_labels': labels}\n\ntrain_data = read_ner_data('/kaggle/input/ner-vn-2023/train.txt')\ntest_data = read_ner_data('/kaggle/input/ner-vn-2023/test.txt')\ndev_data = read_ner_data('/kaggle/input/ner-vn-2023/dev.txt')\n\nprint(\"First 5 lines of the train dataset:\")\nfor i in range(5):\n    print(train_data['sentences'][i], train_data['ner_labels'][i])\n\n# print(\"First 10 lines of the test dataset:\")\n# for i in range(10):\n#     print(test_data['sentences'][i], test_data['ner_labels'][i])\n\n# print(\"First 10 lines of the dev dataset:\")\n# for i in range(10):\n#     print(dev_data['sentences'][i], dev_data['ner_labels'][i])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:25:35.167941Z","iopub.execute_input":"2023-11-12T16:25:35.168185Z","iopub.status.idle":"2023-11-12T16:25:35.708167Z","shell.execute_reply.started":"2023-11-12T16:25:35.168163Z","shell.execute_reply":"2023-11-12T16:25:35.707216Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"First 5 lines of the train dataset:\n['Đó', 'là', 'con', 'đường', 'biển', 'ngắn', 'nhất', 'để', 'đi', 'từ', 'sang', ',', 'chiếm', 'đến', 'lượng', 'của', ',', 'đó', 'là', 'lớn', 'nhất', 'từ', 'tây', 'sang', 'đông', 'với', '50.000', 'lượt', 'mỗi', 'năm', '...'] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n['Một', 'chuyến', 'xuyên', 'ba', 'nước', 'Malaysia', ',', 'Singapore', ',', 'Indonesia', 'vừa', 'được', ',', 'để', 'điều', 'mà', 'các', 'tàu', 'đã', 'mỗi', 'khi', 'nghe', 'nhắc', 'tới', ':', 'Malacca', '!', '...'] ['O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O']\n['Từ', 'bức', 'điện', 'của', 'IMB', '...'] ['O', 'O', 'O', 'O', 'B-ORG', 'O']\n['ngay', 'khi', 'nhận', 'được', 'email', 'của', 'ngài', 'Noel', 'Choong', '-', 'trưởng', 'của', '(', 'IMB', ')', 'tại', 'Malaysia', '-', 'tiếp', 'để', 'những', 'mới', 'nhất', 'về', 'Malacca', '.'] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O']\n['Ông', 'còn', 'trong', ':', '“', 'Phải', 'vì', 'đã', 'như', 'một', ',', 'hãy', 'đến', 'ngay', 'của', 'IMB', ',', 'đừng', 'đến', 'những', 'nơi', '...', '”', '.'] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Xác định số lượng nhãn duy nhất và tạo từ điển ánh xạ\nunique_labels = set(label for sublist in train_data['ner_labels'] for label in sublist)\nnum_labels = len(unique_labels)\nlabel2id = {label: id for id, label in enumerate(unique_labels)}\nid2label = {id: label for label, id in label2id.items()}","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:25:35.709457Z","iopub.execute_input":"2023-11-12T16:25:35.710235Z","iopub.status.idle":"2023-11-12T16:25:35.730887Z","shell.execute_reply.started":"2023-11-12T16:25:35.710198Z","shell.execute_reply":"2023-11-12T16:25:35.730089Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def add_encodings(example):\n    # Mã hóa các token\n    encodings = tokenizer(example['sentences'], truncation=True, padding='max_length', is_split_into_words=True)\n    # Chuyển đổi nhãn NER thành chỉ số\n    labels = [label2id[label] for label in example['ner_labels']]\n    # Thêm nhãn phụ để đảm bảo độ dài nhất quán\n    labels += [-100] * (tokenizer.model_max_length - len(labels))  # Sử dụng -100 để bỏ qua trong tính toán loss\n    encodings['labels'] = labels  # Add labels to the encodings dictionary\n    return encodings","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:25:35.734352Z","iopub.execute_input":"2023-11-12T16:25:35.734646Z","iopub.status.idle":"2023-11-12T16:25:35.740435Z","shell.execute_reply.started":"2023-11-12T16:25:35.734621Z","shell.execute_reply":"2023-11-12T16:25:35.739524Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_encodings = [add_encodings({\"sentences\": s, \"ner_labels\": l}) for s, l in zip(train_data['sentences'], train_data['ner_labels'])]\ntest_encodings = [add_encodings({\"sentences\": s, \"ner_labels\": l}) for s, l in zip(test_data['sentences'], test_data['ner_labels'])]\ndev_encodings = [add_encodings({\"sentences\": s, \"ner_labels\": l}) for s, l in zip(dev_data['sentences'], dev_data['ner_labels'])]","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:25:35.741441Z","iopub.execute_input":"2023-11-12T16:25:35.741785Z","iopub.status.idle":"2023-11-12T16:25:49.509797Z","shell.execute_reply.started":"2023-11-12T16:25:35.741753Z","shell.execute_reply":"2023-11-12T16:25:49.509056Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Khởi tạo mô hình với số lượng nhãn\nmodel = RobertaForTokenClassification.from_pretrained(roberta_version, num_labels=num_labels)\nmodel.config.id2label = id2label\nmodel.config.label2id = label2id","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:25:49.510856Z","iopub.execute_input":"2023-11-12T16:25:49.511208Z","iopub.status.idle":"2023-11-12T16:26:05.113798Z","shell.execute_reply.started":"2023-11-12T16:25:49.511172Z","shell.execute_reply":"2023-11-12T16:26:05.112888Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a92bca14fcb4ea899e05fd871e64bc1"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# model","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:26:05.117134Z","iopub.execute_input":"2023-11-12T16:26:05.117527Z","iopub.status.idle":"2023-11-12T16:26:05.121458Z","shell.execute_reply.started":"2023-11-12T16:26:05.117490Z","shell.execute_reply":"2023-11-12T16:26:05.120630Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def create_dataloader(encodings):\n    input_ids = [enc['input_ids'] for enc in encodings]\n    attention_masks = [enc['attention_mask'] for enc in encodings]\n    labels = [enc['labels'] for enc in encodings]\n    \n    dataset = TensorDataset(torch.tensor(input_ids),\n                            torch.tensor(attention_masks),\n                            torch.tensor(labels))\n    \n    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n    \n    # Convert each batch to a dictionary\n    dataloader = [{'input_ids': batch[0],\n                   'attention_mask': batch[1],\n                   'labels': batch[2]} for batch in dataloader]\n    \n    return dataloader\n\n# Tạo DataLoader cho tập huấn luyện, kiểm thử và phát triển\ntrain_loader = create_dataloader(train_encodings)\ntest_loader = create_dataloader(test_encodings)\ndev_loader = create_dataloader(dev_encodings)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:26:05.122700Z","iopub.execute_input":"2023-11-12T16:26:05.123029Z","iopub.status.idle":"2023-11-12T16:26:15.271175Z","shell.execute_reply.started":"2023-11-12T16:26:05.122998Z","shell.execute_reply":"2023-11-12T16:26:15.270388Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\n# Xác định thiết bị cho huấn luyện\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Đặt mô hình ở chế độ huấn luyện và chuyển nó đến thiết bị\nmodel.train().to(device)\n\n# Khởi tạo bộ tối ưu hóa\noptimizer = optim.AdamW(params=model.parameters(), lr=1e-5)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:26:15.272267Z","iopub.execute_input":"2023-11-12T16:26:15.272548Z","iopub.status.idle":"2023-11-12T16:26:18.273401Z","shell.execute_reply.started":"2023-11-12T16:26:15.272524Z","shell.execute_reply":"2023-11-12T16:26:18.272459Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"n_epochs = 3  # Số lượng epoch\ntrain_loss = []\n\nfor epoch in tqdmn(range(n_epochs)):\n    current_loss = 0\n    for i, batch in enumerate(tqdmn(train_loader)):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs[0]\n        loss.backward()\n\n        current_loss += loss.item()\n        if i % 8 == 0 and i > 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            train_loss.append(current_loss / 32)\n            current_loss = 0\n    \n    optimizer.step()\n    optimizer.zero_grad()\n\n# Trực quan hóa loss huấn luyện\nfig, ax = plt.subplots(figsize=(10, 4))\nax.plot(train_loss)\nax.set_ylabel('Loss')\nax.set_xlabel('Iterations (32 examples)')\nfig.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:26:18.275191Z","iopub.execute_input":"2023-11-12T16:26:18.275485Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aa90b0f07a84017bb5fdbf68d935040"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/929 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8325f275b0b74668b6bc0d3816d94a52"}},"metadata":{}}]},{"cell_type":"code","source":"# Lưu mô hình sau khi quá trình huấn luyện hoàn tất\noutput_model_file = \"./kaggle/working/vietnamese_ner_model.bin\"  # Đường dẫn lưu mô hình\noutput_config_file = \"./kaggle/working/bert_config.json\"  # Đường dẫn lưu cấu hình","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_to_save = model.module if hasattr(model, 'module') else model  # Xử lý cho DataParallel\ntorch.save(model_to_save.state_dict(), output_model_file)\nmodel_to_save.config.to_json_file(output_config_file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}